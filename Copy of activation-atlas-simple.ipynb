{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of activation-atlas-simple.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/lucid/blob/master/notebooks/activation-atlas/activation-atlas-simple.ipynb","timestamp":1588808435105}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GZ445mkXmmlw","colab_type":"text"},"source":["##### Copyright 2018 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","metadata":{"id":"Vvm12KVNmpHF","colab_type":"code","colab":{}},"source":["# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9m2El_OQmrtl","colab_type":"text"},"source":["# Simple Activation Atlas\n","\n","This notebook uses  [**Lucid**](https://github.com/tensorflow/lucid) to reproduce the results in [Activation Atlas](https://distill.pub/2019/activation-atlas/).\n","\n","This notebook doesn't introduce the abstractions behind lucid; you may wish to also read the [Lucid tutorial](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/tutorial.ipynb).\n","\n","**Note**: The easiest way to use this tutorial is as a [colab notebook](https://research.google.com/colaboratory/faq.html), which allows you to dive in with no setup. We recommend you enable a free GPU by going:\n","\n","> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"]},{"cell_type":"markdown","metadata":{"id":"cFty6x9TsKF4","colab_type":"text"},"source":["## Install and imports"]},{"cell_type":"code","metadata":{"id":"1FurXxSnDPmZ","colab_type":"code","colab":{}},"source":["!pip -q install lucid>=0.3.8\n","!pip -q install umap-learn>=0.3.7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CajKvRKOz9FR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"outputId":"e35a4a0d-57ca-4174-8aae-cb89114276de","executionInfo":{"status":"error","timestamp":1588808476643,"user_tz":-180,"elapsed":12249,"user":{"displayName":"Александър Първанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFKYuRjKLQ-ZrNFQLy12VlK_tq5WmKd3o1LVZvWw=s64","userId":"17577702864456554850"}}},"source":["# General support\n","import math\n","import tensorflow as tf\n","import numpy as np\n","\n","# For plots\n","import matplotlib.pyplot as plt\n","\n","# Dimensionality reduction\n","import umap\n","from sklearn.manifold import TSNE\n","\n","# General lucid code\n","from lucid.misc.io import save, show, load\n","import lucid.modelzoo.vision_models as models\n","\n","# For rendering feature visualizations\n","import lucid.optvis.objectives as objectives\n","import lucid.optvis.param as param\n","import lucid.optvis.render as render\n","import lucid.optvis.transform as transform"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-62b208107a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# General lucid code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelzoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lucid/misc/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lucid/misc/io/loading.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlucid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lucid/misc/io/reading.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtempfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgettempdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'gfile'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"lWWTyaFssdi_","colab_type":"text"},"source":["## Load model and activations"]},{"cell_type":"code","metadata":{"id":"DANLrY2E1H5b","colab_type":"code","colab":{}},"source":["model = models.InceptionV1()\n","model.load_graphdef()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdHWsVmvGJFg","colab_type":"code","colab":{}},"source":["# model.layers[7] is \"mixed4c\"\n","layer = \"mixed4c\"\n","print(model.layers[7])\n","raw_activations = model.layers[7].activations\n","activations = raw_activations[:100000]\n","print(activations.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TxcqO-31tJw1","colab_type":"text"},"source":["## Whiten"]},{"cell_type":"code","metadata":{"id":"OKCWPHMMtekV","colab_type":"code","colab":{}},"source":["def whiten(full_activations):\n","    correl = np.matmul(full_activations.T, full_activations) / len(full_activations)\n","    correl = correl.astype(\"float32\")\n","    S = np.linalg.inv(correl)\n","    S = S.astype(\"float32\")\n","    return S"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aLr-E6tAS5t","colab_type":"code","colab":{}},"source":["S = whiten(raw_activations)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcH1MffQtMQ2","colab_type":"text"},"source":["## Dimensionality reduction"]},{"cell_type":"code","metadata":{"id":"6tBMyg63CbUh","colab_type":"code","colab":{}},"source":["def normalize_layout(layout, min_percentile=1, max_percentile=99, relative_margin=0.1):\n","    \"\"\"Removes outliers and scales layout to between [0,1].\"\"\"\n","\n","    # compute percentiles\n","    mins = np.percentile(layout, min_percentile, axis=(0))\n","    maxs = np.percentile(layout, max_percentile, axis=(0))\n","\n","    # add margins\n","    mins -= relative_margin * (maxs - mins)\n","    maxs += relative_margin * (maxs - mins)\n","\n","    # `clip` broadcasts, `[None]`s added only for readability\n","    clipped = np.clip(layout, mins, maxs)\n","\n","    # embed within [0,1] along both axes\n","    clipped -= clipped.min(axis=0)\n","    clipped /= clipped.max(axis=0)\n","\n","    return clipped"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fX44OAJhLk09","colab_type":"code","colab":{}},"source":["layout = umap.UMAP(n_components=2, verbose=True, n_neighbors=20, min_dist=0.01, metric=\"cosine\").fit_transform(activations)\n","\n","## You can optionally use TSNE as well\n","# layout = TSNE(n_components=2, verbose=True, metric=\"cosine\", learning_rate=10, perplexity=50).fit_transform(d)\n","\n","layout = normalize_layout(layout)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iqCtrD6KLvHF","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","plt.scatter(x=layout[:,0],y=layout[:,1], s=2)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DhSQ0aictUu0","colab_type":"text"},"source":["## Feature visualization"]},{"cell_type":"code","metadata":{"id":"0xriaL-bA1kr","colab_type":"code","colab":{}},"source":["# \n","# Whitened, euclidean neuron objective\n","# \n","@objectives.wrap_objective\n","def direction_neuron_S(layer_name, vec, batch=None, x=None, y=None, S=None):\n","    def inner(T):\n","        layer = T(layer_name)\n","        shape = tf.shape(layer)\n","        x_ = shape[1] // 2 if x is None else x\n","        y_ = shape[2] // 2 if y is None else y\n","        if batch is None:\n","            raise RuntimeError(\"requires batch\")\n","\n","        acts = layer[batch, x_, y_]\n","        vec_ = vec\n","        if S is not None: vec_ = tf.matmul(vec_[None], S)[0]\n","        # mag = tf.sqrt(tf.reduce_sum(acts**2))\n","        dot = tf.reduce_mean(acts * vec_)\n","        # cossim = dot/(1e-4 + mag)\n","        return dot\n","    return inner\n","\n","# \n","# Whitened, cosine similarity objective\n","# \n","@objectives.wrap_objective\n","def direction_neuron_cossim_S(layer_name, vec, batch=None, x=None, y=None, cossim_pow=1, S=None):\n","    def inner(T):\n","        layer = T(layer_name)\n","        shape = tf.shape(layer)\n","        x_ = shape[1] // 2 if x is None else x\n","        y_ = shape[2] // 2 if y is None else y\n","        if batch is None:\n","          raise RuntimeError(\"requires batch\")\n","\n","        acts = layer[batch, x_, y_]\n","        vec_ = vec\n","        if S is not None: vec_ = tf.matmul(vec_[None], S)[0]\n","        mag = tf.sqrt(tf.reduce_sum(acts**2))\n","        dot = tf.reduce_mean(acts * vec_)\n","        cossim = dot/(1e-4 + mag)\n","        cossim = tf.maximum(0.1, cossim)\n","        return dot * cossim ** cossim_pow\n","    return inner\n","\n","#\n","# Renders a batch of activations as icons\n","#\n","def render_icons(directions, model, layer, size=80, n_steps=128, verbose=False, S=None, num_attempts=2, cossim=True, alpha=True):\n","    image_attempts = []\n","    loss_attempts = []\n","\n","    # Render multiple attempts, and pull the one with the lowest loss score.\n","    for attempt in range(num_attempts):\n","\n","      # Render an image for each activation vector\n","      param_f = lambda: param.image(size, batch=directions.shape[0], fft=True, decorrelate=True, alpha=alpha)\n","      if(S is not None):\n","          if(cossim is True):\n","              obj_list = ([\n","                direction_neuron_cossim_S(layer, v, batch=n, S=S, cossim_pow=4) for n,v in enumerate(directions)\n","              ]) \n","          else: \n","              obj_list = ([\n","                direction_neuron_S(layer, v, batch=n, S=S) for n,v in enumerate(directions)\n","              ])    \n","      else: \n","          obj_list = ([\n","            objectives.direction_neuron(layer, v, batch=n) for n,v in enumerate(directions)\n","          ])\n","\n","      obj = objectives.Objective.sum(obj_list)\n","\n","      transforms = []\n","      if alpha:\n","          transforms.append(transform.collapse_alpha_random())\n","      transforms.append(transform.pad(2, mode='constant', constant_value=1))\n","      transforms.append(transform.jitter(4))\n","      transforms.append(transform.jitter(4))\n","      transforms.append(transform.jitter(8))\n","      transforms.append(transform.jitter(8))\n","      transforms.append(transform.jitter(8))\n","      transforms.append(transform.random_scale([0.995**n for n in range(-5,80)] + [0.998**n for n in 2*list(range(20,40))]))\n","      transforms.append(transform.random_rotate(list(range(-20,20))+list(range(-10,10))+list(range(-5,5))+5*[0]))\n","      transforms.append(transform.jitter(2))\n","\n","      # This is the tensorflow optimization process.\n","      # We can't use the lucid helpers here because we need to know the loss.\n","\n","      print(\"attempt: \", attempt)\n","      with tf.Graph().as_default(), tf.Session() as sess:\n","          learning_rate = 0.05\n","          losses = []\n","          trainer = tf.train.AdamOptimizer(learning_rate)\n","          T = render.make_vis_T(model, obj, param_f, trainer, transforms)\n","          loss_t, vis_op, t_image = T(\"loss\"), T(\"vis_op\"), T(\"input\")\n","          losses_ = [obj_part(T) for obj_part in obj_list]\n","          tf.global_variables_initializer().run()\n","          for i in range(n_steps):\n","              loss, _ = sess.run([losses_, vis_op])\n","              losses.append(loss)\n","              if (i % 100 == 0):\n","                  print(i)\n","\n","          img = t_image.eval()\n","          img_rgb = img[:,:,:,:3]\n","          if alpha:\n","              print(\"alpha true\")\n","              k = 0.8\n","              bg_color = 0.0\n","              img_a = img[:,:,:,3:]\n","              img_merged = img_rgb*((1-k)+k*img_a) + bg_color * k*(1-img_a)\n","              image_attempts.append(img_merged)\n","          else:\n","              print(\"alpha false\")\n","              image_attempts.append(img_rgb)\n","\n","          loss_attempts.append(losses[-1])\n","\n","    # Use the icon with the lowest loss\n","    loss_attempts = np.asarray(loss_attempts)   \n","    loss_final = []\n","    image_final = []\n","    print(\"Merging best scores from attempts...\")\n","    for i, d in enumerate(directions):\n","        # note, this should be max, it is not a traditional loss\n","        mi = np.argmax(loss_attempts[:,i])\n","        image_final.append(image_attempts[mi][i])\n","\n","    return (image_final, loss_final)\n","  \n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iahKgED3tRci","colab_type":"text"},"source":["## Grid"]},{"cell_type":"code","metadata":{"id":"7sVaNDMYtqGH","colab_type":"code","colab":{}},"source":["# \n","# Takes a list of x,y layout and bins them into grid cells\n","# \n","def grid(xpts=None, ypts=None, grid_size=(8,8), x_extent=(0., 1.), y_extent=(0., 1.)):\n","    xpx_length = grid_size[0]\n","    ypx_length = grid_size[1]\n","\n","    xpt_extent = x_extent\n","    ypt_extent = y_extent\n","\n","    xpt_length = xpt_extent[1] - xpt_extent[0]\n","    ypt_length = ypt_extent[1] - ypt_extent[0]\n","\n","    xpxs = ((xpts - xpt_extent[0]) / xpt_length) * xpx_length\n","    ypxs = ((ypts - ypt_extent[0]) / ypt_length) * ypx_length\n","\n","    ix_s = range(grid_size[0])\n","    iy_s = range(grid_size[1])\n","    xs = []\n","    for xi in ix_s:\n","        ys = []\n","        for yi in iy_s:\n","            xpx_extent = (xi, (xi + 1))\n","            ypx_extent = (yi, (yi + 1))\n","\n","            in_bounds_x = np.logical_and(xpx_extent[0] <= xpxs, xpxs <= xpx_extent[1])\n","            in_bounds_y = np.logical_and(ypx_extent[0] <= ypxs, ypxs <= ypx_extent[1])\n","            in_bounds = np.logical_and(in_bounds_x, in_bounds_y)\n","\n","            in_bounds_indices = np.where(in_bounds)[0]\n","            ys.append(in_bounds_indices)\n","        xs.append(ys)\n","    return np.asarray(xs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPMmZCYhhf2X","colab_type":"code","colab":{}},"source":["def render_layout(model, layer, S, xs, ys, activ, n_steps=512, n_attempts=2, min_density=10, grid_size=(10, 10), icon_size=80, x_extent=(0., 1.0), y_extent=(0., 1.0)):\n","    grid_layout = grid(xpts=xs, ypts=ys, grid_size=grid_size, x_extent=x_extent, y_extent=y_extent)\n","    icons = []\n","\n","    for x in range(grid_size[0]):\n","        for y in range(grid_size[1]):\n","            indices = grid_layout[x, y]\n","            if len(indices) > min_density:\n","                average_activation = np.average(activ[indices], axis=0)\n","                icons.append((average_activation, x, y))\n","\n","    icons = np.asarray(icons)\n","    icon_batch, losses = render_icons(icons[:,0], model, alpha=False, layer=layer, S=S, n_steps=n_steps, size=icon_size, num_attempts=n_attempts)\n","\n","    canvas = np.ones((icon_size * grid_size[0], icon_size * grid_size[1], 3))\n","    for i, icon in enumerate(icon_batch):\n","        y = int(icons[i, 1])\n","        x = int(icons[i, 2])\n","        canvas[(grid_size[0] - x - 1) * icon_size:(grid_size[0] - x) * icon_size, (y) * icon_size:(y + 1) * icon_size] = icon\n","\n","    return canvas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8nivjCy9GGZb","colab_type":"code","colab":{}},"source":["# \n","# Given a layout, renders an icon for the average of all the activations in each grid cell.\n","# \n","\n","xs = layout[:, 0]\n","ys = layout[:, 1]\n","canvas = render_layout(model, layer, S, xs, ys, raw_activations, n_steps=512, grid_size=(20, 20), n_attempts=1)\n","show(canvas)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRaN7S95IbGs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}