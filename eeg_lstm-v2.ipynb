{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"eeg_lstm-v2.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"6eGtk4AvOh68","colab_type":"text"},"source":["## Event Classification from EEG\n","#### Tyrome Sweet and Taran Rallings"]},{"cell_type":"markdown","metadata":{"id":"97-vOh5nOh6-","colab_type":"text"},"source":["### Introduction\n"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"deuzRw9tOh6_","colab_type":"text"},"source":["The following analyes EEG data taken in experiments where participants where exposed to light and sound events. This code cleans that 32 channel EEG data and uses a long short-term memory recurrent neural network to classify the time following light or sound events by which event occured. "]},{"cell_type":"markdown","metadata":{"id":"cjaMG846Oh7A","colab_type":"text"},"source":["### Data Prep\n","\n"]},{"cell_type":"code","metadata":{"id":"koDbxqNmOh7B","colab_type":"code","colab":{}},"source":["# setting the random seed for reproducibility\n","import random\n","seed=42\n","random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJzOYDnMOh7H","colab_type":"code","colab":{}},"source":["# import libraries \n","import itertools\n","import numpy as np\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NU9DHOASOh7L","colab_type":"text"},"source":["### Load the Data"]},{"cell_type":"code","metadata":{"id":"HFUdKLQLO-Np","colab_type":"code","colab":{}},"source":["url1 = 'https://github.com/YYx00xZZ/UniBIT-Study/blob/colab/data/input/1_GD_Standart_14ch_24.01.2020.csv?raw=true'\n","url2 = 'https://github.com/YYx00xZZ/UniBIT-Study/blob/master/data/input/2_GD_Standart_14ch_24.01.2020.csv?raw=true'\n","initial_col_names = ['Time128Hz', 'Epoch', 'AF3', 'F7', 'F3', 'F5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4', 'EventId', 'EventDate', 'EventDuration']\n","initial_ch_names = ['AF3', 'F7', 'F3', 'F5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJqsdpnmOh7M","colab_type":"code","colab":{}},"source":["# eeg1 and events1 are the test data from a single person\n","# code assumes eeg1 and events1 are csv files in the current working directory\n","\n","eeg1 = pd.read_csv(\"/content/clean_df1.csv\", delimiter=\",\")\n","# new_columns = eeg1.columns.values \n","# new_columns[0] = 'time'     \n","# new_columns[33] = 'sample' \n","# eeg1.columns = new_columns\n","\n","# events1 = pd.read_csv(\"events1.csv\") #, delimiter=\"\\t\"\n","events1 = eeg1['EventId']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJ_7bMjFOh7Q","colab_type":"code","colab":{}},"source":["# subsample of the data to ease building the model, unused in final run\n","eeg1_smol = eeg1[0:15220]\n","events1_smol = events1[0:15220]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXrJNk0-Oh7U","colab_type":"code","colab":{}},"source":["# Toy data generator, unused in final run\n","\n","def generate_eeg(samples, time_steps, n_features, event_types):\n","    # samples is Int number of trials \n","    # time_steps is Int length of each trial in ms\n","    # n_features is Int number of EEG channels\n","    # event_types is Int number of stimula like lights and flashes\n","    signals = generate_signals(samples, time_steps, n_features)\n","    events = generate_events(event_types, samples)\n","    events_1hot = one_hot_events(events)\n","    return signals, events_1hot\n","\n","# helper function (generate_eeg) for making EEG signal data\n","def generate_signals(samples, time_steps, n_features):\n","    # data types same as main function\n","    signals = np.random.random((samples, time_steps, n_features))\n","    return signals\n","\n","# helper function (generate_eeg) for making one sample per event an\n","def generate_events(event_types, samples):\n","    # data types same as main function\n","    events = np.random.randint(1, event_types, samples)\n","    return events"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-o1Z6foOh7Y","colab_type":"code","colab":{}},"source":["# takes in eeg dataframe and event dataframe, cleans them, 1hot encodes the events\n","def clean_eeg(eeg, events, event_interval_length, eeg_slice_length):\n","    #event_list = []\n","    array_list = [] \n","    index_list = []\n","    eeg = standardize_eeg(eeg) # function for standardizing the eeg readings\n","    #events_new = build_zero_events(events)\n","    # iterate over the rows of the events and slice out the corresponding eeg data\n","    for index, row in itertools.islice(events.iterrows(), event_interval_length): # loop through events data\n","        #build_event_list(row, event_list) #\n","        tmin, tmax = build_event_intervals(row, events)\n","        eeg_slice = cut_event_intervals(eeg, tmin, tmax)\n","        array_list, index_list = build_array(eeg_slice, eeg_slice_length, \n","                                             index, index_list, array_list)\n","    y_int = events.iloc[index_list] # take the event types for the correct index\n","    y_int = y_int['type'].values    # take just the event types as an array\n","    #y_int = y_int.as_matrix()            # save the event types as a matrix\n","    #y, lb = one_hot_events(y_int)        # one-hot the event types and save the binarizer\n","    X = np.stack(array_list, axis = 0)   # stack the arrays so the whole thing is 3D\n","    return X, y_int                     # return the data, outputs, and the binarizer\n","    \n","        \n","def build_event_list(row, event_list):\n","    # helper function to pull event types out of event data in the right order\n","    event_type = getattr(row, \"type\")\n","    event_list.append(event_type)\n","        \n","def build_event_intervals(row, events):\n","    # helper function to get the time intervals associated with each event\n","    tmin = getattr(row, \"latency\")\n","    tmin_in = getattr(row, \"number\")\n","    tmax_in = tmin_in + 1\n","    tmax = events1.loc[tmax_in, \"latency\"]\n","    return tmin, tmax\n","\n","def cut_event_intervals(eeg, tmin, tmax):\n","    # helper function to slice up the eeg data so each slice is associated with one event\n","    eeg_slice = eeg.loc[(eeg[\"time\"] > tmin) & (eeg[\"time\"] < tmax)]\n","    eeg_slice.drop([\"time\", \"sample\"], axis = 1, inplace = True)\n","    return eeg_slice\n","    \n","def build_array(eeg_slice, eeg_slice_length, index, index_list, array_list):\n","    # helper function to build an array out of the eeg slices and pad them out to a standard length\n","    if len(eeg_slice) < eeg_slice_length:\n","        index_list.append(index)\n","        eeg_matrix = eeg_slice.as_matrix()\n","        padded_matrix = np.pad(eeg_matrix, ((0, eeg_slice_length - len(eeg_matrix)), (0,0)),\n","                                   'constant', constant_values=0)\n","        array_list.append(padded_matrix)\n","    return array_list, index_list\n","\n","def one_hot_events(events):\n","    # helper function for one-hot encoding the events\n","    events_list = list(events)\n","    lb = preprocessing.LabelBinarizer()\n","    lb.fit(events_list)\n","    events_1hot = lb.transform(events_list)\n","    return events_1hot, lb\n","\n","def invert_one_hot(events, lb):\n","    # function for decoding one-hot, binarizer made in one_hot_events\n","    inv_events = lb.inverse_transform(events)\n","    return inv_events"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EssSOp2GRbB4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"6d8c12ca-4585-4b84-95d5-3dac3b16ce0e","executionInfo":{"status":"ok","timestamp":1589276778659,"user_tz":-180,"elapsed":808,"user":{"displayName":"Александър Първанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFKYuRjKLQ-ZrNFQLy12VlK_tq5WmKd3o1LVZvWw=s64","userId":"17577702864456554850"}}},"source":["eeg1['Time128Hz']"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         13.835938\n","1         13.843750\n","2         13.851562\n","3         13.859375\n","4         13.867188\n","            ...    \n","15215    557.828125\n","15216    557.835938\n","15217    557.843750\n","15218    557.851562\n","15219    557.859375\n","Name: Time128Hz, Length: 15220, dtype: float64"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"Oo4qz96pOh7d","colab_type":"code","colab":{}},"source":["def standardize_eeg(eeg_data):\n","    # breaks apart an eeg dataframe, scales the eeg readings, and reassmbles it into a dataframe\n","    column_list = eeg_data.columns[1:15]\n","    time = eeg_data['time']\n","    sample = eeg_data['sample']\n","    eeg_array = eeg_data[column_list]\n","    eeg_stnd = scale_data(eeg_array)\n","    eeg_stnd_df = pd.DataFrame(eeg_stnd, index=eeg_data.index, columns=column_list)\n","    eeg_stnd = pd.concat([time, eeg_stnd_df, sample], axis =1)\n","    return eeg_stnd\n","\n","def scale_data(unscaled_data):\n","    # helper function for standardize_eeg, fits a scaler and transforms the data \n","    scaler = StandardScaler()\n","    scaler.fit(unscaled_data)\n","    scaled_data = scaler.transform(unscaled_data)\n","    return scaled_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzG6aM4SOh7k","colab_type":"code","colab":{}},"source":["# This is unused code for breaking up the \"nothing happened\" periods of the eeg data \n","# to associate with \"type 0\" events. \n","\n","import math\n","time_steps = 1300\n","\n","def build_zero_events(event_data, time_steps=time_steps):\n","    new_events = build_new_events(event_data, time_steps)\n","    events = zero_events(event_data, new_events)\n","    return events\n","\n","\n","def build_new_events(event_data, time_steps= time_steps):\n","    first_event_time = event_data['latency'].loc[1]\n","    number_new_intervals = math.floor(first_event_time / time_steps)\n","    df = pd.DataFrame(columns=['number', 'latency', 'type', 'duration'],index = range(number_new_intervals) )\n","    latency = 0\n","    for t in range(number_new_intervals):\n","        latency += 1300\n","        df.loc[t].latency = latency\n","        df.loc[t].type = 0\n","    return df\n","\n","def zero_events(event_data, new_events):\n","    events_zeros = event_data[event_data.latency != 1]\n","    events_zeros= new_events.append(events_zeros)\n","    events_zeros = events_zeros.reset_index(drop=True)\n","    events_zeros['number'] = events_zeros.index + 1\n","    return events_zeros"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACl9XlY7Oh7q","colab_type":"text"},"source":["### Model\n","\n"]},{"cell_type":"code","metadata":{"id":"TAnYfn9QQjFs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7e4cc84a-6337-4306-b890-cbf5881f9882","executionInfo":{"status":"ok","timestamp":1589276724262,"user_tz":-180,"elapsed":728,"user":{"displayName":"Александър Първанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFKYuRjKLQ-ZrNFQLy12VlK_tq5WmKd3o1LVZvWw=s64","userId":"17577702864456554850"}}},"source":["15220 / 128"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["118.90625"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"7GVlTQeVOh7r","colab_type":"code","colab":{}},"source":["# full dataset parameters\n","\n","# define model parameters\n","samples = 3625  # how many trials of eeg data\n","n_features = 14  # how many channels of eeg in each sample\n","time_steps = 3 # how many ms was each sample run for\n","event_types = 2 #len(set(y))  # how many different event types (light, sound, etc) are there # 6 large, 4 smol"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-fhuzLUOh7w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iC4YDgfROh70","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"outputId":"c419c176-6abd-4177-e279-6a76ed003774","executionInfo":{"status":"error","timestamp":1589276744191,"user_tz":-180,"elapsed":1077,"user":{"displayName":"Александър Първанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFKYuRjKLQ-ZrNFQLy12VlK_tq5WmKd3o1LVZvWw=s64","userId":"17577702864456554850"}}},"source":["# get the data into useable form and store as X and y\n","X, y = clean_eeg(eeg1, events1, samples, time_steps)  #4250 long, 998 short, 4330 long enhanced"],"execution_count":26,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'time'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-886821b98055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_eeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#4250 long, 998 short, 4330 long enhanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-555e08fb43c0>\u001b[0m in \u001b[0;36mclean_eeg\u001b[0;34m(eeg, events, event_interval_length, eeg_slice_length)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0marray_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0meeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_eeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# function for standardizing the eeg readings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#events_new = build_zero_events(events)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# iterate over the rows of the events and slice out the corresponding eeg data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-eaa841762e57>\u001b[0m in \u001b[0;36mstandardize_eeg\u001b[0;34m(eeg_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# breaks apart an eeg dataframe, scales the eeg readings, and reassmbles it into a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcolumn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meeg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'time'"]}]},{"cell_type":"code","metadata":{"id":"vqh2K_ZoOh74","colab_type":"code","colab":{}},"source":["# removes the minor event types. There were only a couple hundred examples of each, whereas the used events had a \n","# couple thousand examples\n","remove_list = [0,2,4,5,6]              # designate unwanted event types\n","drop_list = np.isin(y, remove_list)    # create a list of indices associated with unwanted events                  \n","drop_array = np.array(drop_list)       # make the list of indices to drop into an array"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HltDxYxdOh78","colab_type":"code","colab":{}},"source":["# make X, y's with the unwanted events removed\n","y_short_int = y[np.isin(y,remove_list, invert=True)]\n","X_short = X[np.isin(y, remove_list, invert=True)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"54nESHQfOh8A","colab_type":"code","colab":{}},"source":["# one hot encode the y data without the unwanted events\n","y_short, lb = one_hot_events(y_short_int) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZ8akzKeOh8E","colab_type":"code","colab":{},"outputId":"f35cfeed-df16-4248-8151-44d36f7d3b1d"},"source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# use strat. shuffle split to get indices for test and training data \n","sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=seed)\n","sss.get_n_splits(X_short, y_short)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"G_XI8QdCOh8I","colab_type":"code","colab":{}},"source":["# take the indices generated by stratified shuffle split and make the test and training datasets\n","for train_index, test_index in sss.split(X_short, y_short):\n","    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","    X_train, X_test = X_short[train_index], X_short[test_index]\n","    y_train, y_test = y_short[train_index], y_short[test_index]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzSHE6zWOh8L","colab_type":"code","colab":{},"outputId":"0a3ab0fe-d7f7-407a-a773-56df4c3ae236"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.layers import Embedding\n","from keras.layers import LSTM\n","\n","\n","# code for building an LSTM with 100 neurons and dropout. Runs for 50 epochs\n","\n","model = Sequential()\n","model.add(LSTM(100, return_sequences=False, input_shape=(time_steps, n_features)))\n","model.add(Dropout(0.5))\n","#model.add(LSTM(100)) dramatically worse results\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, batch_size=16, epochs=50)\n","score = model.evaluate(X_test, y_test, batch_size=16)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.6797 - acc: 0.5966\n","Epoch 2/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.6744 - acc: 0.5978\n","Epoch 3/50\n","2444/2444 [==============================] - 89s 36ms/step - loss: 0.6774 - acc: 0.5949\n","Epoch 4/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.6755 - acc: 0.5974\n","Epoch 5/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.6746 - acc: 0.5941\n","Epoch 6/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.6726 - acc: 0.5974\n","Epoch 7/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.6728 - acc: 0.5962\n","Epoch 8/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.6746 - acc: 0.5990\n","Epoch 9/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.6641 - acc: 0.5998\n","Epoch 10/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.6565 - acc: 0.6117\n","Epoch 11/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.6482 - acc: 0.6244\n","Epoch 12/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.6362 - acc: 0.6588\n","Epoch 13/50\n","2444/2444 [==============================] - 103s 42ms/step - loss: 0.6170 - acc: 0.6772\n","Epoch 14/50\n","2444/2444 [==============================] - 120s 49ms/step - loss: 0.6057 - acc: 0.6952\n","Epoch 15/50\n","2444/2444 [==============================] - 107s 44ms/step - loss: 0.5828 - acc: 0.7193\n","Epoch 16/50\n","2444/2444 [==============================] - 104s 43ms/step - loss: 0.5613 - acc: 0.7345\n","Epoch 17/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.5466 - acc: 0.7541\n","Epoch 18/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.5585 - acc: 0.7369\n","Epoch 19/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.5161 - acc: 0.7762\n","Epoch 20/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.5025 - acc: 0.7815\n","Epoch 21/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.5028 - acc: 0.7844\n","Epoch 22/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.4593 - acc: 0.8081\n","Epoch 23/50\n","2444/2444 [==============================] - 93s 38ms/step - loss: 0.4517 - acc: 0.8159\n","Epoch 24/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.4370 - acc: 0.8355\n","Epoch 25/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.4267 - acc: 0.8245\n","Epoch 26/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.4536 - acc: 0.8142\n","Epoch 27/50\n","2444/2444 [==============================] - 89s 36ms/step - loss: 0.3935 - acc: 0.8474\n","Epoch 28/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.3910 - acc: 0.8531\n","Epoch 29/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.3441 - acc: 0.8711\n","Epoch 30/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.3409 - acc: 0.8793\n","Epoch 31/50\n","2444/2444 [==============================] - 93s 38ms/step - loss: 0.3353 - acc: 0.8818\n","Epoch 32/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.3258 - acc: 0.8912\n","Epoch 33/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.3134 - acc: 0.8895\n","Epoch 34/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.3098 - acc: 0.8944\n","Epoch 35/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.2832 - acc: 0.9063\n","Epoch 36/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.2607 - acc: 0.9108\n","Epoch 37/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.2477 - acc: 0.9210\n","Epoch 38/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.2257 - acc: 0.9259\n","Epoch 39/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.2193 - acc: 0.9284\n","Epoch 40/50\n","2444/2444 [==============================] - 92s 38ms/step - loss: 0.2474 - acc: 0.9194\n","Epoch 41/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.1983 - acc: 0.9345\n","Epoch 42/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.2084 - acc: 0.9390\n","Epoch 43/50\n","2444/2444 [==============================] - 93s 38ms/step - loss: 0.2007 - acc: 0.9296\n","Epoch 44/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.2197 - acc: 0.9341\n","Epoch 45/50\n","2444/2444 [==============================] - 93s 38ms/step - loss: 0.1765 - acc: 0.9489\n","Epoch 46/50\n","2444/2444 [==============================] - 92s 37ms/step - loss: 0.1899 - acc: 0.9419\n","Epoch 47/50\n","2444/2444 [==============================] - 90s 37ms/step - loss: 0.1719 - acc: 0.9489\n","Epoch 48/50\n","2444/2444 [==============================] - 89s 37ms/step - loss: 0.1890 - acc: 0.9407\n","Epoch 49/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.1537 - acc: 0.9542\n","Epoch 50/50\n","2444/2444 [==============================] - 91s 37ms/step - loss: 0.1692 - acc: 0.9538\n","612/612 [==============================] - 4s 7ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RBI3g3jAOh8P","colab_type":"code","colab":{},"outputId":"997d9503-756c-4948-ea0d-acc9a07d931d"},"source":["score"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.65204278495333168, 0.80882352941176472]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"GIrDMEU-Oh8S","colab_type":"code","colab":{},"outputId":"accd9cfb-91e5-4e28-e9ef-615fd9f6fa6f"},"source":["print(\"Accuracy: %.2f%%\" % (score[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 80.88%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"829PJj-fOh8W","colab_type":"text"},"source":["#### saved model details\n","standardized\n","\n","model = Sequential()\n","#model.add(Embedding(2, output_dim=256))\n","model.add(LSTM(100, input_shape=(time_steps, n_features)))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, batch_size=16, epochs=50)\n","score = model.evaluate(X_test, y_test, batch_size=16)\n","\n","This model run for 50 epochs had:\n","\n","* binary crossentropy 0.41922928811677918\n","\n","* accuracy 0.8529411764705882"]},{"cell_type":"markdown","metadata":{"id":"MIwTbQUGOh8W","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"z0wF3oucOh8X","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}